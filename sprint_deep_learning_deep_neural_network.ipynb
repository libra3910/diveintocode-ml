{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sprint_deep_learning_deep_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/libra3910/diveintocode-ml/blob/master/sprint_deep_learning_deep_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWWKTXFweOFP"
      },
      "source": [
        "# Sprint 深層学習スクラッチ ディープニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAxIkkvKeOFb"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9K9WkcheOFd"
      },
      "source": [
        "# Utilityクラス\n",
        "# GetMiniBatch\n",
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self._stop\n",
        "    \n",
        "    def __getitem__(self,item):\n",
        "        \n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        \n",
        "        return self._X[p0:p1], self._y[p0:p1]   \n",
        "    \n",
        "    def __iter__(self):\n",
        "        \n",
        "        self._counter = 0\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        \n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        \n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BRbenP-eOFe"
      },
      "source": [
        "# Initializerクラス\n",
        "# SimpleInitializer 【問題2】初期化方法のクラス化\n",
        "class SimpleInitializer:\n",
        "    \n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-sYfledeOFf"
      },
      "source": [
        "# Xavier\n",
        "class Xavier:\n",
        "    \"\"\"\n",
        "    初期値を正規分布化するため、前層のノード数の根で除算する。\n",
        "    活性化関数がシグモイド関数やハイパボリックタンジェント関数の場合に適用。\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2) * (1 / np.sqrt(n_nodes1))\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wKf1wK-eOFg"
      },
      "source": [
        "# He\n",
        "class He:\n",
        "    \"\"\"\n",
        "    （2×前層のノード数の根）で除算する。\n",
        "    活性化関数がReLU関数の場合に適用。\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2) * (2 / np.sqrt(n_nodes1))\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgs23q-SeOFh"
      },
      "source": [
        "# Optimizerクラス\n",
        "# SGD\n",
        "class SGD:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        \n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, layer):\n",
        "\n",
        "        layer.W -= self.lr * np.dot(layer.X.T, layer.dA)\n",
        "        layer.B -= self.lr * np.sum(layer.dA, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW6k4TqHeOFi"
      },
      "source": [
        "# AdaGrad\n",
        "class AdaGrad:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        \n",
        "        self.lr = lr\n",
        "        self.HiW = 0\n",
        "        self.HiB = 0\n",
        "        \n",
        "    def update(self, layer):\n",
        "        \n",
        "        self.HiW += layer.dAW ** 2\n",
        "        self.HiB += layer.dAB ** 2\n",
        "        \n",
        "        layer.W -= self.lr * (1 / (np.sqrt(self.HiW) + 1e-7)) * layer.dAW\n",
        "        layer.B -= self.lr * (1 / (np.sqrt(self.HiB) + 1e-7)) * layer.dAB\n",
        "        \n",
        "        return\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oh_KB6teOFi"
      },
      "source": [
        "# Layerクラス\n",
        "# FC\n",
        "class FC:\n",
        "\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # 初期化\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "\n",
        "        self.W = self.initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = self.initializer.B(n_nodes2)\n",
        "        self.X = None\n",
        "        self.dA = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "\n",
        "        self.X = X\n",
        "        A = np.dot(self.X, self.W) + self.B\n",
        "        return A\n",
        "    \n",
        "    def backward(self, dA):\n",
        "\n",
        "        self.dA = dA\n",
        "\n",
        "        self.dAW = np.dot(self.X.T, self.dA)\n",
        "        self.dAB = np.sum(self.dA, axis=0)\n",
        "        \n",
        "        dz = np.dot(dA, self.W.T)\n",
        "        \n",
        "        self = self.optimizer.update(self)\n",
        "\n",
        "        return dz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChVP4IYneOFj"
      },
      "source": [
        "# ReLU\n",
        "class ReLU:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.A = None\n",
        "    \n",
        "    def forward(self, X):\n",
        "  \n",
        "        self.A = np.copy(X)\n",
        "        \n",
        "        return np.maximum(0, X)\n",
        "        \n",
        "    def backward(self, dA):\n",
        "\n",
        "        return np.where(self.A > 0, dA, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEAUuJq1eOFk"
      },
      "source": [
        "# Tanh\n",
        "class Tanh:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.Z = (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))\n",
        "        return self.Z\n",
        "        \n",
        "    def backward(self, dA):\n",
        "        \n",
        "        dA2 = dA * (1 - self.Z**2)\n",
        "        \n",
        "        return dA2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0sMMlZUeOFl"
      },
      "source": [
        "# Softmax\n",
        "class Softmax:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        pass\n",
        "    \n",
        "    def forward(self, X):\n",
        "        \n",
        "        dz = np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True)\n",
        "        return dz\n",
        "    \n",
        "    def backward(self, Z3, y):\n",
        "\n",
        "        y_one_hot = (y.reshape(-1,1)==np.arange(10))\n",
        "        dza = (Z3 - y) / y.shape[0]\n",
        "        #【問題3】交差エントロピー誤差の実装\n",
        "        L = np.sum(np.mean(-(y_one_hot * Z3), axis=0))\n",
        "        C = np.sum(np.array(dza).argmax(axis=1) == y)\n",
        "        \n",
        "        return dza, L, C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylAzPrrYeOFm"
      },
      "source": [
        "# Calculates log(sum(exp(x)))\n",
        "class logsumexp:\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        \n",
        "        xmax = X.max(axis=1, keepdims=True)\n",
        "        self.Z = np.log(np.exp(X - xmax).sum(axis=1, keepdims=True)) + xmax\n",
        "        \n",
        "        return self.Z\n",
        "\n",
        "    def backward(self, Z3, log_Z3, y):\n",
        "\n",
        "        y_one_hot = (y.reshape(-1,1)==np.arange(10))\n",
        "        dza = (Z3 - y_one_hot) / y_one_hot.shape[0]\n",
        "\n",
        "        L = np.sum(np.mean(-(y_one_hot * log_Z3), axis=0))\n",
        "        C = np.sum(Z3.argmax(axis=1) == y)\n",
        "        \n",
        "        return dza, L, C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UweCJMGNeOFm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Tranerクラス\n",
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    Trainerクラスの定義\n",
        "    \n",
        "    \"\"\"\n",
        "    # self.sigma : ガウス分布の標準偏差\n",
        "    # self.lr : 学習率\n",
        "    # self.n_nodes1 : 1層目のノード数\n",
        "    # self.n_nodes2 : 2層目のノード数\n",
        "    # self.n_output : 出力層のノード数\n",
        "    \n",
        "    batch_size = 20\n",
        "    sigma = 0.01\n",
        "    n_features = 784\n",
        "    n_nodes1 = 400\n",
        "    n_nodes2 = 200\n",
        "    n_output = 10\n",
        "    lr = 0.01\n",
        "\n",
        "    def __init__(self, seed=0, verbose = True, verbose2 = False):\n",
        "        \n",
        "        self.seed = 0\n",
        "        self.verbose = verbose\n",
        "        self.verbose2 = verbose2\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None, pinit=\"Initializer\", pact1=\"Tanh\", pact2=\"logsumexp\", popt=\"SGD\"):    \n",
        "\n",
        "        # 初期化関数\n",
        "        if pinit == \"Initializer\":\n",
        "            initializer = SimpleInitializer(self.sigma, self.seed)\n",
        "        elif pinit == \"Xavier\":\n",
        "            initializer = Xavier(self.sigma, self.seed)\n",
        "        elif pinit == \"He\":\n",
        "            initializer = He(self.sigma, self.seed)\n",
        "        \n",
        "        # 最適化関数\n",
        "        if popt == \"SGD\":\n",
        "            optimizer = SGD(self.lr)\n",
        "        elif popt == \"AdaGrad\":\n",
        "            optimizer1 = AdaGrad(self.lr) \n",
        "            optimizer2 = AdaGrad(self.lr) \n",
        "            optimizer3 = AdaGrad(self.lr) \n",
        "        \n",
        "        # 活性化関数1\n",
        "        if pact1 == \"Tanh\":\n",
        "            self.activation1 = Tanh()\n",
        "            self.activation2 = Tanh()\n",
        "        if pact1 == \"ReLU\":\n",
        "            self.activation1 = ReLU()\n",
        "            self.activation2 = ReLU()\n",
        "\n",
        "        # 活性化関数2\n",
        "        if pact2 == \"logsumexp\":\n",
        "            self.activation3 = logsumexp()\n",
        "        elif pact2 == \"Softmax\":\n",
        "            self.activation3 = Softmax()\n",
        "        \n",
        "        # 学習用関数初期化\n",
        "        if popt == \"SGD\":\n",
        "            self.FC1 = FC(self.n_features, self.n_nodes1, initializer, optimizer) # W1: (784, 400)\n",
        "            self.FC2 = FC(self.n_nodes1, self.n_nodes2, initializer, optimizer) # W2: (400, 200) \n",
        "            self.FC3 = FC(self.n_nodes2, self.n_output, initializer, optimizer) # W3: (200, 10)\n",
        "        elif popt == \"AdaGrad\":\n",
        "            self.FC1 = FC(self.n_features, self.n_nodes1, initializer, optimizer1) # W1: (784, 400)\n",
        "            self.FC2 = FC(self.n_nodes1, self.n_nodes2, initializer, optimizer2) # W2: (400, 200) \n",
        "            self.FC3 = FC(self.n_nodes2, self.n_output, initializer, optimizer3) # W3: (200, 10)            \n",
        "        \n",
        "        epoch = 20\n",
        "        n_step_iteration_report = 500\n",
        "        plot_data = []\n",
        "        \n",
        "        # Utility(epochごとに、全データ分ミニバッチを取得)\n",
        "        for i in range(epoch):\n",
        "\n",
        "            sum_of_loss = 0\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size = self.batch_size)\n",
        "            for j, (mini_X_train, mini_y_train) in enumerate(get_mini_batch):\n",
        "                \n",
        "                # 学習用Forward Propergation\n",
        "                A1 = self.FC1.forward(mini_X_train)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                log_Z3 = A3 - self.activation3.forward(A3)\n",
        "                Z3 = np.exp(log_Z3)\n",
        "                \n",
        "                # 学習用Back Propergation\n",
        "                dA3,L,C = self.activation3.backward(Z3, log_Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
        "                dZ2 = self.FC3.backward(dA3)\n",
        "                dA2 = self.activation2.backward(dZ2)\n",
        "                dZ1 = self.FC2.backward(dA2)\n",
        "                dA1 = self.activation1.backward(dZ1)\n",
        "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
        "                \n",
        "                # ログ出力\n",
        "                sum_of_loss += L\n",
        "                if self.verbose and (j + 1) % n_step_iteration_report == 0:\n",
        "                    train_loss = sum_of_loss / n_step_iteration_report\n",
        "\n",
        "                    # 検証用Forward Propergation、損失、Accuracy\n",
        "                    A1 = self.FC1.forward(X_val)\n",
        "                    Z1 = self.activation1.forward(A1)\n",
        "                    A2 = self.FC2.forward(Z1)\n",
        "                    Z2 = self.activation2.forward(A2)\n",
        "                    A3 = self.FC3.forward(Z2)\n",
        "                    log_Z3 = A3 - self.activation3.forward(A3)\n",
        "                    Z3 = np.exp(log_Z3)\n",
        "\n",
        "                    dA3,val_loss,val_accuracy = self.activation3.backward(Z3, log_Z3, y_val)\n",
        "                    \n",
        "                    print(f'epoch: {i+1}, iteration: {j+1}, train_loss: {train_loss:.3}, val_loss: {val_loss:.3}, accuracty: {val_accuracy / len(y_val):.3}')\n",
        "                    sum_of_loss = 0\n",
        "\n",
        "                    iters_per_epoch = len(X_train) / self.batch_size\n",
        "                    print(\"iters_per_epoch={}\".format(iters_per_epoch))\n",
        "                    plot_data.append((i + (j + 1) / iters_per_epoch, train_loss, val_loss))\n",
        "                \n",
        "            if self.verbose:\n",
        "                #verboseをTrueにした際は学習過程などを出力する\n",
        "                pass\n",
        "                \n",
        "                if self.verbose2:\n",
        "                    print(\"epoch={}\".format(i))\n",
        "                    print(\"forward propergation\")                    \n",
        "                    print(\" A1={}\".format(A1))\n",
        "                    print(\" Z1={}\".format(Z1))\n",
        "                    print(\" A2={}\".format(A2))\n",
        "                    print(\" Z2={}\".format(Z2))\n",
        "                    print(\" A3={}\".format(A3))\n",
        "                    print(\" Z3={}\".format(Z3))\n",
        "                    print(\"back propergation\")\n",
        "                    print(\"dA3={}\".format(dA3))                    \n",
        "                    print(\"dZ2={}\".format(dZ2))\n",
        "                    print(\"dA2={}\".format(dA2))\n",
        "                    print(\"dZ1={}\".format(dZ1))\n",
        "                    print(\"dA1={}\".format(dA1))\n",
        "                    print(\"dA0={}\".format(dA0)) \n",
        "                    \n",
        "        if self.verbose:\n",
        "            #verboseをTrueにした際は学習過程などを出力する\n",
        "            epochs, train_loss, val_loss = zip(*plot_data)\n",
        "            plt.plot(epochs, train_loss, color='r', label='train_loss')\n",
        "            plt.plot(epochs, val_loss, color='b', label='val_loss')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.show()\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        log_Z3 = A3 - self.activation3.forward(A3)\n",
        "        y_pred = log_Z3.argmax(axis=1)\n",
        "        \n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DE7cch_eOFr"
      },
      "source": [
        "# データセットをダウンロードするコード\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NRXCmBmeOFt"
      },
      "source": [
        "# 平滑化\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwXo_545eOFu",
        "outputId": "564a0366-2907-4958-df18-92ff1de484c0"
      },
      "source": [
        "# 前処理\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liQEbLd2eOFv",
        "outputId": "d8e9b6c4-9d2f-4d85-e80d-613738c2deee"
      },
      "source": [
        "y_train_one_hot = (y_train.reshape(-1,1) == np.arange(10)).astype(np.float64)\n",
        "y_test_one_hot = (y_train.reshape(-1,1) == np.arange(10)).astype(np.float64)\n",
        "print(y_train.shape)\n",
        "print(y_train_one_hot.shape)\n",
        "print(y_train_one_hot.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObeUuPC8eOFw",
        "outputId": "492676ee-4c41-4b7a-e992-af3f5e2ab82d"
      },
      "source": [
        "def split_data(X, permutation, val_size_rate=0.2):\n",
        "    X = X[permutation]\n",
        "    val_size = int(len(X) * val_size_rate)\n",
        "    val = X[:val_size]\n",
        "    train = X[val_size:]\n",
        "    return train, val\n",
        "\n",
        "permutation = np.random.permutation(np.arange(len(X_train)))\n",
        "X_train, X_val = split_data(X_train, permutation)\n",
        "y_train, y_val = split_data(y_train, permutation)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(48000,)\n",
            "(12000, 784)\n",
            "(12000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw-UX27ueOFw",
        "outputId": "e113c5ab-7fad-4972-95e3-d26e238ece4e"
      },
      "source": [
        "dnnc = ScratchDeepNeuralNetrowkClassifier()\n",
        "dnnc.fit(X_train, y_train, X_val, y_val, pinit=\"Initializer\", pact1=\"Tanh\", pact2=\"logsumexp\", popt=\"SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, iteration: 500, train_loss: 2.29, val_loss: 2.28, accuracty: 0.359\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1000, train_loss: 2.23, val_loss: 2.08, accuracty: 0.354\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1500, train_loss: 1.66, val_loss: 1.27, accuracty: 0.595\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 2000, train_loss: 1.01, val_loss: 0.827, accuracty: 0.761\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 500, train_loss: 0.626, val_loss: 0.58, accuracty: 0.833\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1000, train_loss: 0.546, val_loss: 0.513, accuracty: 0.855\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1500, train_loss: 0.488, val_loss: 0.466, accuracty: 0.867\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 2000, train_loss: 0.451, val_loss: 0.433, accuracty: 0.879\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 500, train_loss: 0.408, val_loss: 0.396, accuracty: 0.889\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1000, train_loss: 0.383, val_loss: 0.381, accuracty: 0.893\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1500, train_loss: 0.374, val_loss: 0.369, accuracty: 0.895\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 2000, train_loss: 0.363, val_loss: 0.359, accuracty: 0.9\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 500, train_loss: 0.353, val_loss: 0.345, accuracty: 0.901\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1000, train_loss: 0.334, val_loss: 0.339, accuracty: 0.902\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1500, train_loss: 0.332, val_loss: 0.332, accuracty: 0.904\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 2000, train_loss: 0.327, val_loss: 0.327, accuracty: 0.906\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 500, train_loss: 0.323, val_loss: 0.317, accuracty: 0.909\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1000, train_loss: 0.305, val_loss: 0.312, accuracty: 0.91\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1500, train_loss: 0.304, val_loss: 0.306, accuracty: 0.912\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 2000, train_loss: 0.301, val_loss: 0.304, accuracty: 0.912\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 500, train_loss: 0.3, val_loss: 0.294, accuracty: 0.916\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1000, train_loss: 0.282, val_loss: 0.29, accuracty: 0.917\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1500, train_loss: 0.281, val_loss: 0.285, accuracty: 0.918\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 2000, train_loss: 0.278, val_loss: 0.284, accuracty: 0.918\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 500, train_loss: 0.279, val_loss: 0.275, accuracty: 0.921\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1000, train_loss: 0.262, val_loss: 0.271, accuracty: 0.921\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1500, train_loss: 0.26, val_loss: 0.266, accuracty: 0.924\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 2000, train_loss: 0.257, val_loss: 0.266, accuracty: 0.923\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 500, train_loss: 0.26, val_loss: 0.258, accuracty: 0.925\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1000, train_loss: 0.244, val_loss: 0.254, accuracty: 0.926\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1500, train_loss: 0.242, val_loss: 0.25, accuracty: 0.928\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 2000, train_loss: 0.239, val_loss: 0.25, accuracty: 0.927\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 500, train_loss: 0.243, val_loss: 0.242, accuracty: 0.929\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1000, train_loss: 0.227, val_loss: 0.239, accuracty: 0.931\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1500, train_loss: 0.226, val_loss: 0.236, accuracty: 0.932\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 2000, train_loss: 0.223, val_loss: 0.236, accuracty: 0.932\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 500, train_loss: 0.226, val_loss: 0.228, accuracty: 0.933\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1000, train_loss: 0.212, val_loss: 0.225, accuracty: 0.935\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1500, train_loss: 0.211, val_loss: 0.222, accuracty: 0.935\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 2000, train_loss: 0.208, val_loss: 0.222, accuracty: 0.935\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 500, train_loss: 0.211, val_loss: 0.215, accuracty: 0.936\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1000, train_loss: 0.198, val_loss: 0.213, accuracty: 0.938\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1500, train_loss: 0.197, val_loss: 0.209, accuracty: 0.939\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 2000, train_loss: 0.193, val_loss: 0.209, accuracty: 0.939\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 500, train_loss: 0.197, val_loss: 0.203, accuracty: 0.94\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1000, train_loss: 0.185, val_loss: 0.201, accuracty: 0.942\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1500, train_loss: 0.184, val_loss: 0.198, accuracty: 0.944\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 2000, train_loss: 0.18, val_loss: 0.197, accuracty: 0.943\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 500, train_loss: 0.184, val_loss: 0.192, accuracty: 0.944\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1000, train_loss: 0.172, val_loss: 0.19, accuracty: 0.945\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1500, train_loss: 0.172, val_loss: 0.187, accuracty: 0.946\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 2000, train_loss: 0.168, val_loss: 0.186, accuracty: 0.946\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 500, train_loss: 0.172, val_loss: 0.182, accuracty: 0.948\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1000, train_loss: 0.161, val_loss: 0.181, accuracty: 0.947\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1500, train_loss: 0.162, val_loss: 0.178, accuracty: 0.949\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 2000, train_loss: 0.158, val_loss: 0.176, accuracty: 0.95\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 500, train_loss: 0.161, val_loss: 0.173, accuracty: 0.95\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1000, train_loss: 0.151, val_loss: 0.172, accuracty: 0.951\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1500, train_loss: 0.152, val_loss: 0.17, accuracty: 0.951\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 2000, train_loss: 0.148, val_loss: 0.168, accuracty: 0.952\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 500, train_loss: 0.152, val_loss: 0.165, accuracty: 0.953\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1000, train_loss: 0.142, val_loss: 0.165, accuracty: 0.953\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1500, train_loss: 0.143, val_loss: 0.162, accuracty: 0.954\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 2000, train_loss: 0.139, val_loss: 0.16, accuracty: 0.954\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 500, train_loss: 0.143, val_loss: 0.158, accuracty: 0.954\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1000, train_loss: 0.133, val_loss: 0.158, accuracty: 0.955\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1500, train_loss: 0.135, val_loss: 0.155, accuracty: 0.955\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 2000, train_loss: 0.131, val_loss: 0.153, accuracty: 0.955\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 500, train_loss: 0.135, val_loss: 0.151, accuracty: 0.956\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1000, train_loss: 0.125, val_loss: 0.152, accuracty: 0.957\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1500, train_loss: 0.128, val_loss: 0.149, accuracty: 0.957\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 2000, train_loss: 0.123, val_loss: 0.146, accuracty: 0.957\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 500, train_loss: 0.127, val_loss: 0.145, accuracty: 0.958\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1000, train_loss: 0.118, val_loss: 0.146, accuracty: 0.958\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1500, train_loss: 0.121, val_loss: 0.144, accuracty: 0.958\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 2000, train_loss: 0.116, val_loss: 0.141, accuracty: 0.958\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 500, train_loss: 0.12, val_loss: 0.14, accuracty: 0.959\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1000, train_loss: 0.111, val_loss: 0.141, accuracty: 0.959\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1500, train_loss: 0.115, val_loss: 0.138, accuracty: 0.959\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 2000, train_loss: 0.11, val_loss: 0.136, accuracty: 0.96\n",
            "iters_per_epoch=2400.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So8pSfQfeOFx",
        "outputId": "511f5d2d-9b4b-4aba-d3c3-5d45ed4b0bf8"
      },
      "source": [
        "dnnc = ScratchDeepNeuralNetrowkClassifier()\n",
        "dnnc.fit(X_train, y_train, X_val, y_val, pinit=\"Xavier\", pact1=\"Tanh\", pact2=\"logsumexp\", popt=\"SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 500, train_loss: 2.29, val_loss: 2.29, accuracty: 0.188\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1000, train_loss: 2.21, val_loss: 2.05, accuracty: 0.208\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1500, train_loss: 1.96, val_loss: 1.9, accuracty: 0.234\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 2000, train_loss: 1.85, val_loss: 1.81, accuracty: 0.262\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 500, train_loss: 1.73, val_loss: 1.71, accuracty: 0.293\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1000, train_loss: 1.69, val_loss: 1.68, accuracty: 0.315\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1500, train_loss: 1.66, val_loss: 1.65, accuracty: 0.336\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 2000, train_loss: 1.62, val_loss: 1.6, accuracty: 0.385\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 500, train_loss: 1.5, val_loss: 1.45, accuracty: 0.436\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1000, train_loss: 1.4, val_loss: 1.36, accuracty: 0.481\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1500, train_loss: 1.32, val_loss: 1.26, accuracty: 0.536\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 2000, train_loss: 1.19, val_loss: 1.14, accuracty: 0.577\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 500, train_loss: 1.01, val_loss: 0.953, accuracty: 0.677\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1000, train_loss: 0.91, val_loss: 0.88, accuracty: 0.713\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1500, train_loss: 0.851, val_loss: 0.808, accuracty: 0.749\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 2000, train_loss: 0.766, val_loss: 0.742, accuracty: 0.77\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 500, train_loss: 0.682, val_loss: 0.652, accuracty: 0.794\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1000, train_loss: 0.628, val_loss: 0.62, accuracty: 0.809\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1500, train_loss: 0.593, val_loss: 0.579, accuracty: 0.82\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 2000, train_loss: 0.563, val_loss: 0.549, accuracty: 0.834\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 500, train_loss: 0.518, val_loss: 0.495, accuracty: 0.854\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1000, train_loss: 0.477, val_loss: 0.469, accuracty: 0.866\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1500, train_loss: 0.447, val_loss: 0.446, accuracty: 0.871\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 2000, train_loss: 0.437, val_loss: 0.431, accuracty: 0.877\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 500, train_loss: 0.414, val_loss: 0.402, accuracty: 0.885\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1000, train_loss: 0.389, val_loss: 0.389, accuracty: 0.89\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1500, train_loss: 0.376, val_loss: 0.379, accuracty: 0.892\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 2000, train_loss: 0.371, val_loss: 0.374, accuracty: 0.894\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 500, train_loss: 0.362, val_loss: 0.354, accuracty: 0.9\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1000, train_loss: 0.343, val_loss: 0.347, accuracty: 0.903\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1500, train_loss: 0.335, val_loss: 0.339, accuracty: 0.904\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 2000, train_loss: 0.33, val_loss: 0.336, accuracty: 0.907\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 500, train_loss: 0.325, val_loss: 0.32, accuracty: 0.909\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1000, train_loss: 0.308, val_loss: 0.316, accuracty: 0.91\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1500, train_loss: 0.303, val_loss: 0.309, accuracty: 0.912\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 2000, train_loss: 0.299, val_loss: 0.307, accuracty: 0.914\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 500, train_loss: 0.296, val_loss: 0.293, accuracty: 0.917\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1000, train_loss: 0.281, val_loss: 0.291, accuracty: 0.917\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1500, train_loss: 0.277, val_loss: 0.285, accuracty: 0.919\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 2000, train_loss: 0.273, val_loss: 0.283, accuracty: 0.921\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 500, train_loss: 0.272, val_loss: 0.271, accuracty: 0.923\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1000, train_loss: 0.258, val_loss: 0.27, accuracty: 0.922\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1500, train_loss: 0.255, val_loss: 0.263, accuracty: 0.924\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 2000, train_loss: 0.25, val_loss: 0.262, accuracty: 0.927\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 500, train_loss: 0.25, val_loss: 0.251, accuracty: 0.928\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1000, train_loss: 0.237, val_loss: 0.251, accuracty: 0.927\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1500, train_loss: 0.234, val_loss: 0.244, accuracty: 0.93\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 2000, train_loss: 0.229, val_loss: 0.243, accuracty: 0.931\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 500, train_loss: 0.231, val_loss: 0.234, accuracty: 0.933\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1000, train_loss: 0.218, val_loss: 0.234, accuracty: 0.934\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1500, train_loss: 0.216, val_loss: 0.228, accuracty: 0.934\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 2000, train_loss: 0.21, val_loss: 0.226, accuracty: 0.935\n",
            "iters_per_epoch=2400.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT8ovxTleOFx",
        "outputId": "16d322d3-b9f9-4036-b7bf-64e10e4ea7a5"
      },
      "source": [
        "dnnc = ScratchDeepNeuralNetrowkClassifier()\n",
        "dnnc.fit(X_train, y_train, X_val, y_val, pinit=\"He\", pact1=\"ReLU\", pact2=\"logsumexp\", popt=\"SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 2000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 500, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1000, train_loss: 2.3, val_loss: 2.3, accuracty: 0.108\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1500, train_loss: 2.29, val_loss: 2.29, accuracty: 0.171\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 2000, train_loss: 2.26, val_loss: 2.19, accuracty: 0.207\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 500, train_loss: 1.78, val_loss: 1.66, accuracty: 0.347\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1000, train_loss: 1.59, val_loss: 1.54, accuracty: 0.401\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1500, train_loss: 1.52, val_loss: 1.48, accuracty: 0.428\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 2000, train_loss: 1.44, val_loss: 1.38, accuracty: 0.503\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 500, train_loss: 1.07, val_loss: 0.988, accuracty: 0.655\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1000, train_loss: 0.947, val_loss: 0.932, accuracty: 0.663\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1500, train_loss: 0.907, val_loss: 0.878, accuracty: 0.702\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 2000, train_loss: 0.851, val_loss: 0.847, accuracty: 0.711\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 500, train_loss: 0.786, val_loss: 0.722, accuracty: 0.777\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1000, train_loss: 0.681, val_loss: 0.647, accuracty: 0.809\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1500, train_loss: 0.609, val_loss: 0.579, accuracty: 0.831\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 2000, train_loss: 0.563, val_loss: 0.55, accuracty: 0.841\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 500, train_loss: 0.518, val_loss: 0.493, accuracty: 0.861\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1000, train_loss: 0.483, val_loss: 0.48, accuracty: 0.865\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1500, train_loss: 0.459, val_loss: 0.455, accuracty: 0.872\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 2000, train_loss: 0.449, val_loss: 0.447, accuracty: 0.873\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 500, train_loss: 0.431, val_loss: 0.422, accuracty: 0.882\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1000, train_loss: 0.409, val_loss: 0.411, accuracty: 0.885\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1500, train_loss: 0.39, val_loss: 0.391, accuracty: 0.89\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 2000, train_loss: 0.384, val_loss: 0.387, accuracty: 0.891\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 500, train_loss: 0.37, val_loss: 0.367, accuracty: 0.896\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1000, train_loss: 0.35, val_loss: 0.352, accuracty: 0.902\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1500, train_loss: 0.332, val_loss: 0.333, accuracty: 0.907\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 2000, train_loss: 0.321, val_loss: 0.326, accuracty: 0.906\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 500, train_loss: 0.307, val_loss: 0.304, accuracty: 0.914\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1000, train_loss: 0.286, val_loss: 0.289, accuracty: 0.92\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1500, train_loss: 0.271, val_loss: 0.272, accuracty: 0.924\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 2000, train_loss: 0.257, val_loss: 0.267, accuracty: 0.924\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 500, train_loss: 0.252, val_loss: 0.25, accuracty: 0.929\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1000, train_loss: 0.233, val_loss: 0.241, accuracty: 0.933\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1500, train_loss: 0.226, val_loss: 0.23, accuracty: 0.935\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 2000, train_loss: 0.213, val_loss: 0.228, accuracty: 0.935\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 500, train_loss: 0.215, val_loss: 0.217, accuracty: 0.94\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1000, train_loss: 0.199, val_loss: 0.211, accuracty: 0.941\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1500, train_loss: 0.195, val_loss: 0.204, accuracty: 0.942\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 2000, train_loss: 0.184, val_loss: 0.203, accuracty: 0.943\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 500, train_loss: 0.189, val_loss: 0.196, accuracty: 0.943\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1000, train_loss: 0.175, val_loss: 0.19, accuracty: 0.948\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1500, train_loss: 0.173, val_loss: 0.185, accuracty: 0.948\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 2000, train_loss: 0.163, val_loss: 0.185, accuracty: 0.949\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 500, train_loss: 0.169, val_loss: 0.18, accuracty: 0.948\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1000, train_loss: 0.155, val_loss: 0.175, accuracty: 0.952\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1500, train_loss: 0.155, val_loss: 0.172, accuracty: 0.952\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 2000, train_loss: 0.146, val_loss: 0.172, accuracty: 0.952\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 500, train_loss: 0.152, val_loss: 0.168, accuracty: 0.95\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1000, train_loss: 0.14, val_loss: 0.163, accuracty: 0.954\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1500, train_loss: 0.141, val_loss: 0.162, accuracty: 0.955\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 2000, train_loss: 0.132, val_loss: 0.162, accuracty: 0.955\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 500, train_loss: 0.138, val_loss: 0.159, accuracty: 0.952\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1000, train_loss: 0.127, val_loss: 0.154, accuracty: 0.957\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1500, train_loss: 0.129, val_loss: 0.154, accuracty: 0.957\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 2000, train_loss: 0.121, val_loss: 0.153, accuracty: 0.957\n",
            "iters_per_epoch=2400.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECwy1M2UeOFx",
        "outputId": "a45b683f-7ba2-4421-8bd2-cc868a2c9805"
      },
      "source": [
        "dnnc = ScratchDeepNeuralNetrowkClassifier()\n",
        "dnnc.fit(X_train, y_train, X_val, y_val, pinit=\"Initializer\", pact1=\"Tanh\", pact2=\"logsumexp\", popt=\"AdaGrad\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, iteration: 500, train_loss: 0.464, val_loss: 0.286, accuracty: 0.917\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1000, train_loss: 0.261, val_loss: 0.236, accuracty: 0.931\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 1500, train_loss: 0.23, val_loss: 0.214, accuracty: 0.938\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 1, iteration: 2000, train_loss: 0.207, val_loss: 0.195, accuracty: 0.944\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 500, train_loss: 0.17, val_loss: 0.175, accuracty: 0.947\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1000, train_loss: 0.157, val_loss: 0.167, accuracty: 0.952\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 1500, train_loss: 0.155, val_loss: 0.159, accuracty: 0.954\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 2, iteration: 2000, train_loss: 0.145, val_loss: 0.151, accuracty: 0.955\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 500, train_loss: 0.13, val_loss: 0.145, accuracty: 0.956\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1000, train_loss: 0.122, val_loss: 0.142, accuracty: 0.959\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 1500, train_loss: 0.124, val_loss: 0.137, accuracty: 0.96\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 3, iteration: 2000, train_loss: 0.116, val_loss: 0.131, accuracty: 0.96\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 500, train_loss: 0.107, val_loss: 0.128, accuracty: 0.961\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1000, train_loss: 0.101, val_loss: 0.127, accuracty: 0.962\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 1500, train_loss: 0.104, val_loss: 0.123, accuracty: 0.963\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 4, iteration: 2000, train_loss: 0.0971, val_loss: 0.118, accuracty: 0.964\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 500, train_loss: 0.091, val_loss: 0.117, accuracty: 0.965\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1000, train_loss: 0.0856, val_loss: 0.116, accuracty: 0.965\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 1500, train_loss: 0.0907, val_loss: 0.114, accuracty: 0.965\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 5, iteration: 2000, train_loss: 0.0834, val_loss: 0.11, accuracty: 0.967\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 500, train_loss: 0.079, val_loss: 0.109, accuracty: 0.967\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1000, train_loss: 0.0743, val_loss: 0.108, accuracty: 0.967\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 1500, train_loss: 0.0801, val_loss: 0.106, accuracty: 0.967\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 6, iteration: 2000, train_loss: 0.0725, val_loss: 0.103, accuracty: 0.968\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 500, train_loss: 0.0694, val_loss: 0.103, accuracty: 0.968\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1000, train_loss: 0.0654, val_loss: 0.102, accuracty: 0.968\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 1500, train_loss: 0.0716, val_loss: 0.1, accuracty: 0.969\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 7, iteration: 2000, train_loss: 0.0638, val_loss: 0.0978, accuracty: 0.97\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 500, train_loss: 0.0615, val_loss: 0.0985, accuracty: 0.969\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1000, train_loss: 0.0582, val_loss: 0.0972, accuracty: 0.97\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 1500, train_loss: 0.0646, val_loss: 0.0958, accuracty: 0.97\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 8, iteration: 2000, train_loss: 0.0565, val_loss: 0.0936, accuracty: 0.971\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 500, train_loss: 0.0549, val_loss: 0.0946, accuracty: 0.971\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1000, train_loss: 0.0521, val_loss: 0.0933, accuracty: 0.971\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 1500, train_loss: 0.0586, val_loss: 0.0921, accuracty: 0.972\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 9, iteration: 2000, train_loss: 0.0504, val_loss: 0.0903, accuracty: 0.972\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 500, train_loss: 0.0492, val_loss: 0.0913, accuracty: 0.972\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1000, train_loss: 0.047, val_loss: 0.0901, accuracty: 0.972\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 1500, train_loss: 0.0535, val_loss: 0.0891, accuracty: 0.973\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 10, iteration: 2000, train_loss: 0.0451, val_loss: 0.0876, accuracty: 0.973\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 500, train_loss: 0.0443, val_loss: 0.0886, accuracty: 0.973\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1000, train_loss: 0.0426, val_loss: 0.0876, accuracty: 0.973\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 1500, train_loss: 0.0489, val_loss: 0.0865, accuracty: 0.974\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 11, iteration: 2000, train_loss: 0.0406, val_loss: 0.0853, accuracty: 0.974\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 500, train_loss: 0.04, val_loss: 0.0863, accuracty: 0.974\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1000, train_loss: 0.0386, val_loss: 0.0855, accuracty: 0.974\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 1500, train_loss: 0.0449, val_loss: 0.0845, accuracty: 0.974\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 12, iteration: 2000, train_loss: 0.0366, val_loss: 0.0835, accuracty: 0.974\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 500, train_loss: 0.0362, val_loss: 0.0844, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1000, train_loss: 0.0351, val_loss: 0.0837, accuracty: 0.974\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 1500, train_loss: 0.0413, val_loss: 0.0828, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 13, iteration: 2000, train_loss: 0.0331, val_loss: 0.082, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 500, train_loss: 0.0328, val_loss: 0.0828, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1000, train_loss: 0.032, val_loss: 0.0823, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 1500, train_loss: 0.0381, val_loss: 0.0814, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 14, iteration: 2000, train_loss: 0.03, val_loss: 0.0807, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 500, train_loss: 0.0298, val_loss: 0.0815, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1000, train_loss: 0.0292, val_loss: 0.0811, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 1500, train_loss: 0.0352, val_loss: 0.0803, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 15, iteration: 2000, train_loss: 0.0272, val_loss: 0.0797, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 500, train_loss: 0.0272, val_loss: 0.0804, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1000, train_loss: 0.0267, val_loss: 0.0802, accuracty: 0.975\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 1500, train_loss: 0.0326, val_loss: 0.0794, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 16, iteration: 2000, train_loss: 0.0247, val_loss: 0.0789, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 500, train_loss: 0.0248, val_loss: 0.0795, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1000, train_loss: 0.0245, val_loss: 0.0794, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 1500, train_loss: 0.0302, val_loss: 0.0787, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 17, iteration: 2000, train_loss: 0.0226, val_loss: 0.0782, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 500, train_loss: 0.0227, val_loss: 0.0788, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1000, train_loss: 0.0224, val_loss: 0.0788, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 1500, train_loss: 0.028, val_loss: 0.0781, accuracty: 0.977\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 18, iteration: 2000, train_loss: 0.0206, val_loss: 0.0777, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 500, train_loss: 0.0208, val_loss: 0.0783, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1000, train_loss: 0.0206, val_loss: 0.0782, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 1500, train_loss: 0.026, val_loss: 0.0777, accuracty: 0.977\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 19, iteration: 2000, train_loss: 0.0189, val_loss: 0.0772, accuracty: 0.977\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 500, train_loss: 0.0191, val_loss: 0.0779, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1000, train_loss: 0.0189, val_loss: 0.0778, accuracty: 0.976\n",
            "iters_per_epoch=2400.0\n",
            "epoch: 20, iteration: 1500, train_loss: 0.0242, val_loss: 0.0773, accuracty: 0.977\n",
            "iters_per_epoch=2400.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 20, iteration: 2000, train_loss: 0.0173, val_loss: 0.0769, accuracty: 0.977\n",
            "iters_per_epoch=2400.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44oSKAC2eOFy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}