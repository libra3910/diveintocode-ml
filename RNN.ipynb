{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/libra3910/diveintocode-ml/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuVzec_XEw9z"
      },
      "source": [
        "### 【問題1】SimpleRNNのフォワードプロパゲーション実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkdC3ZtBEw99"
      },
      "source": [
        "import numpy as np\n",
        "# Initializerクラス\n",
        "# SimpleInitializer 【問題2】初期化方法のクラス化\n",
        "class SimpleInitializer:\n",
        "    \n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def Wx(self):\n",
        "        \n",
        "        Wx = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # w_x.shape = (2, 4)\n",
        "        \n",
        "        return Wx\n",
        "        \n",
        "    def Wh(self):\n",
        "        \n",
        "        Wh = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # w_h.shape = (4, 4)\n",
        "        \n",
        "        return Wh\n",
        "    \n",
        "    def B(self):\n",
        "        \n",
        "        B = np.array([1, 1, 1, 1]) # B.shape = (1, 4)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HenMjbNEw9_"
      },
      "source": [
        "# Optimizerクラス\n",
        "# SGD\n",
        "class SGD:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        \n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, layer):\n",
        "\n",
        "        layer.W -= self.lr * np.dot(layer.X.T, layer.dA)\n",
        "        layer.B -= self.lr * np.sum(layer.dA, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5342lgjEw9_"
      },
      "source": [
        "# 【問題2】小さな配列でのフォワードプロパゲーションの実験\n",
        "# Layerクラス\n",
        "# FC\n",
        "class FC:\n",
        "\n",
        "    def __init__(self, initializer, optimizer):\n",
        "\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # 初期化\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "\n",
        "        self.Wx = self.initializer.Wx()\n",
        "        self.Wh = self.initializer.Wh()\n",
        "        self.B = self.initializer.B()\n",
        "        self.X = None\n",
        "        self.dA = None\n",
        "        \n",
        "    def forward(self, X, ht1):\n",
        "\n",
        "        self.X = X\n",
        "        self.ht1 = ht1\n",
        "        A = np.dot(self.X, self.Wx) + np.dot(self.ht1, self.Wh) + self.B\n",
        "        \n",
        "        return A\n",
        "\n",
        "# 【問題3】（アドバンス課題）バックプロパゲーションの実装\n",
        "    def backward(self, dA, y):\n",
        "\n",
        "        self.dA = dA\n",
        "        \n",
        "        dz = dA + np.dot(y, self.W.T)\n",
        "        \n",
        "        return dz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpKYVyrcEw-A"
      },
      "source": [
        "# Tanh\n",
        "class Tanh:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.Z = (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))\n",
        "        return self.Z\n",
        "        \n",
        "    def backward(self, dA):\n",
        "        \n",
        "        dA2 = self.Z\n",
        "        \n",
        "        return dA2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWStzY4gEw-B"
      },
      "source": [
        "# Calculates log(sum(exp(x)))\n",
        "class logsumexp:\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        \n",
        "        xmax = X.max(axis=1, keepdims=True)\n",
        "        self.Z = np.log(np.exp(X - xmax).sum(axis=1, keepdims=True)) + xmax\n",
        "        \n",
        "        return self.Z\n",
        "\n",
        "    def backward(self, Z3, log_Z3, y):\n",
        "\n",
        "        y_one_hot = (y.reshape(-1,1)==np.arange(10))\n",
        "        log_Z3 = (Z3 - y_one_hot) / y_one_hot.shape[0]\n",
        "        dZa = np.exp(log_Z3)\n",
        "        \n",
        "        return dza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyZp_w5KEw-B"
      },
      "source": [
        "# Softmax\n",
        "class Softmax:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        pass\n",
        "    \n",
        "    def forward(self, X):\n",
        "        \n",
        "        dz = np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True)\n",
        "        return dz\n",
        "    \n",
        "    def backward(self, Z3, y):\n",
        "\n",
        "        y_one_hot = (y.reshape(-1,1)==np.arange(10))\n",
        "        dza = (Z3 - y) / y.shape[0]\n",
        "        #【問題3】交差エントロピー誤差の実装\n",
        "        L = np.sum(np.mean(-(y_one_hot * Z3), axis=0))\n",
        "        C = np.sum(np.array(dza).argmax(axis=1) == y)\n",
        "        \n",
        "        return dza, L, C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRnprXrfEw-C"
      },
      "source": [
        "# Tranerクラス\n",
        "class SimpleRNN:\n",
        "    \"\"\"\n",
        "    Trainerクラスの定義\n",
        "    \n",
        "    \"\"\"\n",
        "    # self.sigma : ガウス分布の標準偏差\n",
        "    # self.lr : 学習率\n",
        "    # self.n_nodes1 : 1層目のノード数\n",
        "    # self.n_nodes2 : 2層目のノード数\n",
        "    # self.n_output : 出力層のノード数\n",
        "    \n",
        "    sigma = 0.01\n",
        "    lr = 0.01\n",
        "\n",
        "    def __init__(self, seed=0, verbose = True, verbose2 = False):\n",
        "        \n",
        "        self.seed = seed\n",
        "        self.verbose = verbose\n",
        "        self.verbose2 = verbose2\n",
        "        \n",
        "    def fit(self, x, y):\n",
        "        \n",
        "        # 初期値設定\n",
        "\n",
        "        batch_size = x.shape[0] # 1\n",
        "        n_sequences = x.shape[1] # 3\n",
        "        n_features = x.shape[2] # 2\n",
        "        n_nodes = 4 # 4 w_x.shape = (2, 4)\n",
        "        h = np.zeros((batch_size, n_nodes)) # (batch_size=1, n_nodes=4)\n",
        "        print(\"x.shape={}\".format(x.shape))\n",
        "        \n",
        "        # 初期化関数\n",
        "        initializer = SimpleInitializer(self.sigma, self.seed)\n",
        "        \n",
        "        # 最適化関数\n",
        "        optimizer = SGD(self.lr)\n",
        "        \n",
        "        # 活性化関数1\n",
        "        self.activation1 = Tanh()\n",
        "        \n",
        "        # 活性化関数2\n",
        "        self.activation2 = Tanh()\n",
        "        \n",
        "        # 学習用関数初期化\n",
        "        self.FC1 = FC(initializer, optimizer) \n",
        "        \n",
        "        # 学習：forward propergation\n",
        "        for i in range(n_sequences):\n",
        "            \n",
        "            A = self.FC1.forward(x[0][i], h)\n",
        "            print(\"A={}\".format(A))\n",
        "\n",
        "            if i < (n_sequences - 1):\n",
        "                h = self.activation1.forward(A)\n",
        "                print(\"ha={}\".format(h))\n",
        "            else:\n",
        "                h = self.activation2.forward(A)\n",
        "        \n",
        "        print(\"Forward Propergation h={}\".format(h))\n",
        "                \n",
        "        # 学習：back propergation\n",
        "        #for i in range(n_sequences):\n",
        "            \n",
        "            #if i == n_sequences:\n",
        "                #dAh = self.activation2.forward(h)\n",
        "            #else:\n",
        "                #sAh = self.activation2.forward(h)            \n",
        "           \n",
        "            #h = self.FC1.backward(sAh)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQlMxbvaEw-D"
      },
      "source": [
        "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size=1, n_sequences=3, n_features=2)\n",
        "y = np.array([[[1],[2],[3]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkK9K2jDEw-D",
        "outputId": "fc3ac148-54a3-4071-a936-e12a0dac4d30"
      },
      "source": [
        "rnn = SimpleRNN()\n",
        "rnn.fit(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape=(1, 3, 2)\n",
            "A=[[1.0007 1.0013 1.0019 1.0023]]\n",
            "ha=[[0.76188798 0.76213958 0.76239095 0.76255841]]\n",
            "A=[[1.07733574 1.13931527 1.20129481 1.25535044]]\n",
            "ha=[[0.792209   0.8141834  0.83404912 0.84977719]]\n",
            "A=[[1.08471832 1.15192269 1.21912707 1.27759095]]\n",
            "Forward Propergation h=[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSrTuiAjEw-E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}