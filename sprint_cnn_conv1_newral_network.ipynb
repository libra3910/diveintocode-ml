{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "sprint_cnn_conv1_newral_network.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pCBPTFzDtkvO",
        "XNBNUF8utkvQ",
        "qG3ztUCHtkvS",
        "HiKlMRWztkvV",
        "wreKXVSktkvV",
        "ui0GDhLYtkvW",
        "5I-vR9FjtkvX"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/libra3910/diveintocode-ml/blob/master/sprint_cnn_conv1_newral_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npdtJr10tkvC"
      },
      "source": [
        "# Sprint 深層学習スクラッチ ディープニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEjC7nuktkvE"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS8H4osMtkvG"
      },
      "source": [
        "### ミニバッチ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z3UAt3utkvH"
      },
      "source": [
        "# Utilityクラス\n",
        "# GetMiniBatch\n",
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self._stop\n",
        "    \n",
        "    def __getitem__(self,item):\n",
        "        \n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        \n",
        "        return self._X[p0:p1], self._y[p0:p1]   \n",
        "    \n",
        "    def __iter__(self):\n",
        "        \n",
        "        self._counter = 0\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        \n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        \n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNADvQm8tkvI"
      },
      "source": [
        "### 全結合層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Uf-z0btkvI"
      },
      "source": [
        "# Initializerクラス\n",
        "# SimpleInitializer 【問題2】初期化方法のクラス化\n",
        "class SimpleInitializer:\n",
        "    \n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAx_RZGitkvJ"
      },
      "source": [
        "# Xavier\n",
        "class Xavier:\n",
        "    \"\"\"\n",
        "    初期値を正規分布化するため、前層のノード数の根で除算する。\n",
        "    活性化関数がシグモイド関数やハイパボリックタンジェント関数の場合に適用。\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2) * (1 / np.sqrt(n_nodes1))\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIFcoQZPtkvK"
      },
      "source": [
        "# He\n",
        "class He:\n",
        "    \"\"\"\n",
        "    （2×前層のノード数の根）で除算する。\n",
        "    活性化関数がReLU関数の場合に適用。\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2) * (2 / np.sqrt(n_nodes1))\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        \n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLx8bsBhtkvK"
      },
      "source": [
        "# Optimizerクラス\n",
        "# SGD\n",
        "class SGD:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        \n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, layer):\n",
        "\n",
        "        #layer.W -= self.lr * np.dot(layer.X.T, layer.dA)\n",
        "        #layer.B -= self.lr * np.sum(layer.dA, axis=0)\n",
        "        layer.W -= self.lr * layer.dAW\n",
        "        layer.B -= self.lr * layer.dAB\n",
        "        \n",
        "        return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iNWfHuqtkvL"
      },
      "source": [
        "# AdaGrad\n",
        "class AdaGrad:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        \n",
        "        self.lr = lr\n",
        "        self.HiW = 0\n",
        "        self.HiB = 0\n",
        "        \n",
        "    def update(self, layer):\n",
        "        \n",
        "        self.HiW += layer.dAW ** 2\n",
        "        self.HiB += layer.dAB ** 2\n",
        "        \n",
        "        layer.W -= self.lr * (1 / (np.sqrt(self.HiW) + 1e-7)) * layer.dAW\n",
        "        layer.B -= self.lr * (1 / (np.sqrt(self.HiB) + 1e-7)) * layer.dAB\n",
        "        \n",
        "        return layer\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSToes0GtkvL"
      },
      "source": [
        "# Layerクラス\n",
        "# FC\n",
        "class FC:\n",
        "\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # 初期化\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "\n",
        "        self.W = self.initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = self.initializer.B(n_nodes2)\n",
        "        self.X = None\n",
        "        self.dA = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "\n",
        "        self.X = X\n",
        "        A = np.dot(self.X, self.W) + self.B\n",
        "        return A\n",
        "    \n",
        "    def backward(self, dA):\n",
        "\n",
        "        self.dA = dA\n",
        "\n",
        "        self.dAW = np.dot(self.X.T, self.dA)\n",
        "        self.dAB = np.sum(self.dA, axis=0)\n",
        "        \n",
        "        dz = np.dot(dA, self.W.T)\n",
        "        \n",
        "        self = self.optimizer.update(self)\n",
        "\n",
        "        return dz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I72VhBnWtkvM"
      },
      "source": [
        "# ReLU\n",
        "class ReLU:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.A = None\n",
        "    \n",
        "    def forward(self, X):\n",
        "  \n",
        "        self.A = np.copy(X)\n",
        "        \n",
        "        return np.maximum(0, X)\n",
        "        \n",
        "    def backward(self, dA):\n",
        "\n",
        "        return np.where(self.A > 0, dA, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvuo1KbatkvN"
      },
      "source": [
        "# Tanh\n",
        "class Tanh:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.Z = (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))\n",
        "        return self.Z\n",
        "        \n",
        "    def backward(self, dA):\n",
        "        \n",
        "        dA2 = dA * (1 - self.Z**2)\n",
        "        \n",
        "        return dA2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c4SsflbtkvN"
      },
      "source": [
        "# Softmax\n",
        "class Softmax:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        pass\n",
        "    \n",
        "    def forward(self, X):\n",
        "        \n",
        "        dz = np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True)\n",
        "        return dz\n",
        "    \n",
        "    def backward(self, Z3, y):\n",
        "\n",
        "        y_one_hot = (y.reshape(-1,1)==np.arange(10))\n",
        "        dza = (Z3 - y) / y.shape[0]\n",
        "        #【問題3】交差エントロピー誤差の実装\n",
        "        L = np.sum(np.mean(-(y_one_hot * Z3), axis=0))\n",
        "        C = np.sum(np.array(dza).argmax(axis=1) == y)\n",
        "        \n",
        "        return dza, L, C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhrPa_lWtkvO"
      },
      "source": [
        "# Calculates log(sum(exp(x)))\n",
        "class logsumexp:\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        \n",
        "        xmax = X.max(axis=1, keepdims=True)\n",
        "        self.Z = np.log(np.exp(X - xmax).sum(axis=1, keepdims=True)) + xmax\n",
        "        \n",
        "        return self.Z\n",
        "\n",
        "    def backward(self, Z3, log_Z3, y):\n",
        "\n",
        "        y_one_hot = (y.reshape(-1,1)==np.arange(10))\n",
        "        dza = (Z3 - y_one_hot) / y_one_hot.shape[0]\n",
        "\n",
        "        L = np.sum(np.mean(-(y_one_hot * log_Z3), axis=0))\n",
        "        C = np.sum(Z3.argmax(axis=1) == y)\n",
        "        \n",
        "        return dza, L, C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCBPTFzDtkvO"
      },
      "source": [
        "### 畳み込み層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waUTHI0etkvO"
      },
      "source": [
        "# Initializerクラス\n",
        "# SimpleInitializer 【問題2】初期化方法のクラス化\n",
        "class SimpleInitializerConv1d:\n",
        "    \n",
        "    def __init__(self, sigma, seed=0):\n",
        "        \n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(self.seed)\n",
        "        \n",
        "    def W(self, out_channel, in_channel, filter_size):\n",
        "        \n",
        "        W = self.sigma * np.random.randn(out_channel, in_channel, filter_size)\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def B(self, out_channel):\n",
        "        \n",
        "        B = self.sigma * np.random.randn(out_channel)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6QWuQT-tkvP"
      },
      "source": [
        "# 1次元畳み込み層\n",
        "class SimpleConv1d:\n",
        "    \n",
        "    def __init__(self, out_channel, in_channel, filter_size,\n",
        "                padding_size = 0, stride_size = 1,\n",
        "                initializer = None, optimizer = None):\n",
        "        \n",
        "        self.padding_size = padding_size\n",
        "        self.stride_size = stride_size\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "        # 初期化\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "\n",
        "        self.W = self.initializer.W(out_channel, in_channel, filter_size)\n",
        "        self.B = self.initializer.B(out_channel)\n",
        "        self.X = None\n",
        "        self.dA = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "\n",
        "        self.X = X[:, np.newaxis, :]\n",
        "        self.N_out = int((self.X.shape[2] + 2 * self.padding_size - self.W.shape[2]) / self.stride_size) + 1 # 【問題２】1次元畳み込み後の出力サイズの計算\n",
        "        \n",
        "        a = np.array([])\n",
        "        for n in range(self.X.shape[0]):\n",
        "            Yhat = np.array([])\n",
        "            for j in range(self.N_out):\n",
        "                Yhat_tmp = 0\n",
        "                for i in range(self.X.shape[1]): # ストライドする分はループが必要か\n",
        "                    Yhat_tmp += (self.X[n, i, j:j+self.W.shape[2]].dot(self.W[n, i, :])).astype(np.float64)\n",
        "                Yhat = np.append(Yhat, np.sum(Yhat_tmp, axis=0) + self.B[n])\n",
        "\n",
        "            a = np.append(a, Yhat)\n",
        "        \n",
        "        a = a.reshape(self.X.shape[0], self.N_out)\n",
        "\n",
        "        return a\n",
        "        \n",
        "    def backward(self, delta_a):\n",
        "        \n",
        "        delta_a = delta_a[:, np.newaxis, :]\n",
        "        \n",
        "        # Xを更新\n",
        "        self.aX = np.zeros(self.X.shape)\n",
        "        for n in range(self.X.shape[0]):\n",
        "            for j in range(self.W.shape[0]):\n",
        "                for i in range(self.W.shape[1]):\n",
        "                    for h in range(self.W.shape[2]):\n",
        "                        for k in range(self.N_out):\n",
        "                            self.aX[n, i, h+k] += (self.W[j, i, h] * delta_a[n, i, k]).astype(np.float64)\n",
        "\n",
        "        # Wを更新\n",
        "        self.dAW = np.zeros(self.W.shape)\n",
        "        for n in range(self.X.shape[0]):\n",
        "            for j in range(self.W.shape[0]):\n",
        "                for i in range(self.W.shape[1]):\n",
        "                    for h in range(self.W.shape[2]):\n",
        "                        for k in range(self.N_out):\n",
        "                            self.dAW[j, i, h] += (self.X[n, i, h+k] * delta_a[n, i, k]).astype(np.float64)\n",
        "                            \n",
        "        # Bを更新\n",
        "\n",
        "        self.dAB = np.sum(delta_a.reshape(self.X.shape[0], -1), axis=1)\n",
        "\n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return self.aX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNBNUF8utkvQ"
      },
      "source": [
        "### 学習および推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou0_p9-WtkvQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Tranerクラス\n",
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    Trainerクラスの定義\n",
        "    \n",
        "    \"\"\"\n",
        "    # self.sigma : ガウス分布の標準偏差\n",
        "    # self.lr : 学習率\n",
        "    # self.n_nodes1 : 1層目のノード数\n",
        "    # self.n_nodes2 : 2層目のノード数\n",
        "    # self.n_output : 出力層のノード数\n",
        "    \n",
        "    batch_size = 20\n",
        "    sigma = 0.01\n",
        "    n_features = 782\n",
        "    n_nodes1 = 400\n",
        "    n_nodes2 = 200\n",
        "    n_output = 10\n",
        "    lr = 0.01\n",
        "\n",
        "    def __init__(self, seed=0, verbose = True, verbose2 = False):\n",
        "        \n",
        "        self.seed = 0\n",
        "        self.verbose = verbose\n",
        "        self.verbose2 = verbose2\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None, pinit=\"Initializer\", pact1=\"Tanh\", pact2=\"logsumexp\", popt=\"SGD\",\n",
        "            cinit = \"InitializerConv1d\", cact = \"ReLU\", copt = \"SGD\", \n",
        "            out_channel = 20, in_channel = 1, filter_size = 3, padding_size = 0, stride_size = 1):\n",
        "\n",
        "        # 畳み込み層　初期化、学習用の各関数を定義\n",
        "        # 初期化関数\n",
        "        if cinit == \"InitializerConv1d\":\n",
        "            initializerConv1d =SimpleInitializerConv1d(self.sigma, self.seed)\n",
        "        \n",
        "        # 最適化関数\n",
        "        if copt == \"SGD\":\n",
        "            optimizerConv1d = SGD(self.lr)\n",
        "        \n",
        "        # 活性化関数\n",
        "        if cact == \"ReLU\":\n",
        "            self.activationConv1d = ReLU()\n",
        "        \n",
        "        # 学習用関数初期化\n",
        "        if copt == \"SGD\":\n",
        "            self.Conv1d = SimpleConv1d(out_channel, in_channel, filter_size, padding_size, stride_size, \n",
        "                                       initializerConv1d, optimizerConv1d)\n",
        "       \n",
        "        # 全結合層　初期化、最適化、活性化、学習用の各関数を定義\n",
        "        # 初期化関数\n",
        "        if pinit == \"Initializer\":\n",
        "            initializer = SimpleInitializer(self.sigma, self.seed)\n",
        "        elif pinit == \"Xavier\":\n",
        "            initializer = Xavier(self.sigma, self.seed)\n",
        "        elif pinit == \"He\":\n",
        "            initializer = He(self.sigma, self.seed)\n",
        "        \n",
        "        # 最適化関数\n",
        "        if popt == \"SGD\":\n",
        "            optimizer = SGD(self.lr)\n",
        "        elif popt == \"AdaGrad\":\n",
        "            optimizer1 = AdaGrad(self.lr) \n",
        "            optimizer2 = AdaGrad(self.lr) \n",
        "            optimizer3 = AdaGrad(self.lr) \n",
        "        \n",
        "        # 活性化関数1\n",
        "        if pact1 == \"Tanh\":\n",
        "            self.activation1 = Tanh()\n",
        "            self.activation2 = Tanh()\n",
        "        if pact1 == \"ReLU\":\n",
        "            self.activation1 = ReLU()\n",
        "            self.activation2 = ReLU()\n",
        "\n",
        "        # 活性化関数2\n",
        "        if pact2 == \"logsumexp\":\n",
        "            self.activation3 = logsumexp()\n",
        "        elif pact2 == \"Softmax\":\n",
        "            self.activation3 = Softmax()\n",
        "        \n",
        "        # 学習用関数初期化\n",
        "        if popt == \"SGD\":\n",
        "            self.FC1 = FC(self.n_features, self.n_nodes1, initializer, optimizer) # W1: (782, 400)\n",
        "            self.FC2 = FC(self.n_nodes1, self.n_nodes2, initializer, optimizer) # W2: (400, 200) \n",
        "            self.FC3 = FC(self.n_nodes2, self.n_output, initializer, optimizer) # W3: (200, 10)\n",
        "        elif popt == \"AdaGrad\":\n",
        "            self.FC1 = FC(self.n_features, self.n_nodes1, initializer, optimizer1) # W1: (782, 400)\n",
        "            self.FC2 = FC(self.n_nodes1, self.n_nodes2, initializer, optimizer2) # W2: (400, 200) \n",
        "            self.FC3 = FC(self.n_nodes2, self.n_output, initializer, optimizer3) # W3: (200, 10)            \n",
        "        \n",
        "        epoch = 20\n",
        "        n_step_iteration_report = 1\n",
        "        plot_data = []\n",
        "        \n",
        "        # Utility(epochごとに、全データ分ミニバッチを取得)\n",
        "        for i in range(epoch):\n",
        "\n",
        "            sum_of_loss = 0\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size = self.batch_size)\n",
        "            for j, (mini_X_train, mini_y_train) in enumerate(get_mini_batch):\n",
        "                \n",
        "                # 畳み込み層　学習用Forward Propergation\n",
        "                C1  = self.Conv1d.forward(mini_X_train)\n",
        "                ZC1 = self.activationConv1d.forward(C1)\n",
        "                \n",
        "                # 全結合層　学習用Forward Propergation\n",
        "                A1 = self.FC1.forward(ZC1)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                log_Z3 = A3 - self.activation3.forward(A3)\n",
        "                Z3 = np.exp(log_Z3)\n",
        "                \n",
        "                # 全結合層　学習用Back Propergation\n",
        "                dA3,L,C = self.activation3.backward(Z3, log_Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
        "                dZ2 = self.FC3.backward(dA3)\n",
        "                dA2 = self.activation2.backward(dZ2)\n",
        "                dZ1 = self.FC2.backward(dA2)\n",
        "                dA1 = self.activation1.backward(dZ1)\n",
        "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
        "                \n",
        "                # 畳み込み層　学習用Back Propergation\n",
        "                dA0 = self.activationConv1d.backward(dZ0)\n",
        "                dZC = self.Conv1d.backward(dA0)\n",
        "                \n",
        "                # ログ出力\n",
        "                sum_of_loss += L\n",
        "                if self.verbose and (j + 1) % n_step_iteration_report == 0:\n",
        "                    train_loss = sum_of_loss / n_step_iteration_report\n",
        "\n",
        "                    # 検証用Forward Propergation、損失、Accuracy\n",
        "                    #C1  = self.Conv1d.forward(X_val)\n",
        "                    #ZC1 = self.activationConv1d.forward(C1)                    \n",
        "                    #A1 = self.FC1.forward(ZC1)\n",
        "                    #Z1 = self.activation1.forward(A1)\n",
        "                    #A2 = self.FC2.forward(Z1)\n",
        "                    #Z2 = self.activation2.forward(A2)\n",
        "                    #A3 = self.FC3.forward(Z2)\n",
        "                    #log_Z3 = A3 - self.activation3.forward(A3)\n",
        "                    #Z3 = np.exp(log_Z3)\n",
        "\n",
        "                    #dA3,val_loss,val_accuracy = self.activation3.backward(Z3, log_Z3, y_val)\n",
        "                    \n",
        "                    #print(f'epoch: {i+1}, iteration: {j+1}, train_loss: {train_loss:.3}, val_loss: {val_loss:.3}, accuracty: {val_accuracy / len(y_val):.3}')\n",
        "                    print(f'epoch: {i+1}, iteration: {j+1}, train_loss: {train_loss:.3}, accuracy: {C / len(mini_y_train):.3}')\n",
        "                    sum_of_loss = 0\n",
        "\n",
        "                    iters_per_epoch = len(X_train) / self.batch_size\n",
        "                    print(\"iters_per_epoch={}\".format(iters_per_epoch))\n",
        "                    #plot_data.append((i + (j + 1) / iters_per_epoch, train_loss, val_loss))\n",
        "                    plot_data.append((i + (j + 1) / iters_per_epoch, train_loss))\n",
        "                \n",
        "            if self.verbose:\n",
        "                #verboseをTrueにした際は学習過程などを出力する\n",
        "                pass\n",
        "                \n",
        "                if self.verbose2:\n",
        "                    print(\"epoch={}\".format(i))\n",
        "                    print(\"forward propergation\")                    \n",
        "                    print(\" A1={}\".format(A1))\n",
        "                    print(\" Z1={}\".format(Z1))\n",
        "                    print(\" A2={}\".format(A2))\n",
        "                    print(\" Z2={}\".format(Z2))\n",
        "                    print(\" A3={}\".format(A3))\n",
        "                    print(\" Z3={}\".format(Z3))\n",
        "                    print(\"back propergation\")\n",
        "                    print(\"dA3={}\".format(dA3))                    \n",
        "                    print(\"dZ2={}\".format(dZ2))\n",
        "                    print(\"dA2={}\".format(dA2))\n",
        "                    print(\"dZ1={}\".format(dZ1))\n",
        "                    print(\"dA1={}\".format(dA1))\n",
        "                    print(\"dA0={}\".format(dA0)) \n",
        "                    \n",
        "        if self.verbose:\n",
        "            #verboseをTrueにした際は学習過程などを出力する\n",
        "            #epochs, train_loss, val_loss = zip(*plot_data)\n",
        "            epochs, train_loss = zip(*plot_data)\n",
        "            plt.plot(epochs, train_loss, color='r', label='train_loss')\n",
        "            #plt.plot(epochs, val_loss, color='b', label='val_loss')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.show()\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        C1  = self.Conv1d.forward(X)\n",
        "        ZC1 = self.activationConv1d.forward(C1)\n",
        "        A1 = self.FC1.forward(ZC1)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        log_Z3 = A3 - self.activation3.forward(A3)\n",
        "        y_pred = log_Z3.argmax(axis=1)\n",
        "        \n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG3ztUCHtkvS"
      },
      "source": [
        "### 【問題8】学習と推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eDZveVAtkvS"
      },
      "source": [
        "# データセットをダウンロードするコード\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvpmcAu6tkvS"
      },
      "source": [
        "# 平滑化\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xYzDEtYtkvT",
        "outputId": "ce88221f-3b8b-484b-eefd-7a3ac9c2f4b9"
      },
      "source": [
        "# 前処理\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGKyrZtetkvT",
        "outputId": "a2bf1f3e-0c6c-42c3-a66d-ec7d5fc8e7ac"
      },
      "source": [
        "y_train_one_hot = (y_train.reshape(-1,1) == np.arange(10)).astype(np.float64)\n",
        "y_test_one_hot = (y_train.reshape(-1,1) == np.arange(10)).astype(np.float64)\n",
        "print(y_train.shape)\n",
        "print(y_train_one_hot.shape)\n",
        "print(y_train_one_hot.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3C5yVSOtkvU",
        "outputId": "5cf49259-e787-4a2c-9c89-048261bcbcb7"
      },
      "source": [
        "def split_data(X, permutation, val_size_rate=0.90):\n",
        "    X = X[permutation]\n",
        "    val_size = int(len(X) * val_size_rate)\n",
        "    val = X[:val_size]\n",
        "    train = X[val_size:]\n",
        "    return train, val\n",
        "\n",
        "permutation = np.random.permutation(np.arange(len(X_train)))\n",
        "X_train, X_val = split_data(X_train, permutation)\n",
        "y_train, y_val = split_data(y_train, permutation)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60, 784)\n",
            "(60,)\n",
            "(540, 784)\n",
            "(540,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCjIeuzvtkvU",
        "outputId": "b2d8be67-4f91-4546-9545-bf83227ec605"
      },
      "source": [
        "dnnc = ScratchDeepNeuralNetrowkClassifier()\n",
        "dnnc.fit(X_train, y_train, X_val, y_val, pinit=\"Initializer\", pact1=\"Tanh\", pact2=\"logsumexp\", popt=\"SGD\",\n",
        "        cinit = \"InitializerConv1d\", cact = \"ReLU\", copt = \"SGD\",\n",
        "        out_channel = 20, in_channel = 1, filter_size = 3, padding_size = 0, stride_size = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, iteration: 1, train_loss: 2.3, accuracy: 0.1\n",
            "iters_per_epoch=3.0\n",
            "epoch: 1, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 1, iteration: 3, train_loss: 2.3, accuracy: 0.05\n",
            "iters_per_epoch=3.0\n",
            "epoch: 2, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 2, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 2, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 3, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 3, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 3, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 4, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 4, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 4, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 5, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 5, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 5, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 6, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 6, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 6, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 7, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 7, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 7, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 8, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 8, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 8, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 9, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 9, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 9, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 10, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 10, iteration: 2, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 10, iteration: 3, train_loss: 2.3, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 11, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 11, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 11, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 12, iteration: 1, train_loss: 2.3, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 12, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 12, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 13, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 13, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 13, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 14, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 14, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 14, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 15, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 15, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 15, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 16, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 16, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 16, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 17, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 17, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 17, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 18, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 18, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 18, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 19, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 19, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 19, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 20, iteration: 1, train_loss: 2.29, accuracy: 0.15\n",
            "iters_per_epoch=3.0\n",
            "epoch: 20, iteration: 2, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n",
            "epoch: 20, iteration: 3, train_loss: 2.29, accuracy: 0.2\n",
            "iters_per_epoch=3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkluICrbtkvU",
        "outputId": "bf0cea19-b729-4c2e-c09c-992a8b842694"
      },
      "source": [
        "dnnc.predict(X_val[0:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "      dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiKlMRWztkvV"
      },
      "source": [
        "### 【問題2】1次元畳み込み後の出力サイズの計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nINMG07tkvV",
        "outputId": "7ce00373-616e-4b69-c602-1fb0d7406084"
      },
      "source": [
        "X=np.array([1,2,3,4]) # X　入力サイズ\n",
        "W=np.array([3,5,7]) # ウエイト\n",
        "b=1 # バイアス\n",
        "pad=0 #パディング\n",
        "strd=1 #ストライド\n",
        "\n",
        "N_out = int((len(X) + 2*pad - W.shape[0]) / strd) + 1\n",
        "print(N_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wreKXVSktkvV"
      },
      "source": [
        "### 【問題3】小さな配列での1次元畳み込み層の実験"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9_kVrw8tkvV",
        "outputId": "f3230e3f-f991-416e-e484-16f66f19fff2"
      },
      "source": [
        "# Forward Propergation\n",
        "# Xの要素の位置をストライドして計算\n",
        "X=np.array([1,2,3,4])\n",
        "W=np.array([3,5,7])\n",
        "b=1\n",
        "pad=0\n",
        "strd=1\n",
        "\n",
        "N_out = int((len(X) + 2*pad - W.shape[0]) / strd) + 1 # 【問題２】1次元畳み込み後の出力サイズの計算\n",
        "Yhat = np.array([])\n",
        "\n",
        "for i in range(N_out): # ストライドする分はループが必要か\n",
        "    Yhat = np.append(Yhat, int(X[i:i+len(W)].dot(W) + b))\n",
        "print(Yhat.astype(int))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[35 50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzC_SVdotkvV",
        "outputId": "bf840531-b436-4233-fc98-61fb117a60f2"
      },
      "source": [
        "# Back Propergation\n",
        "\n",
        "a=np.zeros([len(X)])\n",
        "delta_a = np.array([10, 20])\n",
        "\n",
        "# Xを更新\n",
        "aX=np.array([])\n",
        "\n",
        "for i in range(N_out): # ストライドする分はループが必要か\n",
        "    a=np.zeros([X.shape[0]])\n",
        "    for j in range(W.shape[0]): # ストライドした分、ずらしながらaに格納するループ\n",
        "        a[j+i]=W[j]\n",
        "    aX = np.append(aX,a).reshape(N_out,-1)\n",
        "aX = delta_a.dot(aX)\n",
        "print(\"aX={}\".format(aX))\n",
        "\n",
        "# Wを更新\n",
        "indexes = np.array([])\n",
        "aW = np.array([])\n",
        "\n",
        "for i in range(N_out): # ストライドする分はループが必要か\n",
        "    indexes = np.append(indexes, [np.arange(i,W.shape[0]+i)]).astype(np.int) # ([[1, 2, 3], [2, 3, 4]])\n",
        "aW = delta_a.reshape(1,-1).dot(X[indexes].reshape(N_out,-1)).reshape(-1)\n",
        "print(\"aW={}\".format(aW))\n",
        "\n",
        "# Bを更新\n",
        "aB = np.sum(delta_a)\n",
        "print(\"aB={}\".format(aB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aX=[ 30. 110. 170. 140.]\n",
            "aW=[ 50  80 110]\n",
            "aB=30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui0GDhLYtkvW"
      },
      "source": [
        "### 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKyZhZjrtkvW"
      },
      "source": [
        "# フォワード\n",
        "X=np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
        "W = np.ones((3, 2, 3))\n",
        "b=np.array([1, 2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oopgWSOHtkvW",
        "outputId": "053b1519-c873-406f-a61f-a0b82c9ede83"
      },
      "source": [
        "# Forward Propergation\n",
        "# Xの要素の位置をストライドして計算\n",
        "\n",
        "pad=0\n",
        "strd=1\n",
        "\n",
        "Yhat = np.array([])\n",
        "\n",
        "N_out = int((X.shape[1] + 2*pad - W.shape[2]) / strd) + 1 # 【問題２】1次元畳み込み後の出力サイズの計算\n",
        "\n",
        "for j in range(W.shape[0]):\n",
        "    for i in range(N_out): # ストライドする分はループが必要か\n",
        "        Yhat_tmp = 0\n",
        "        for h in range(X.shape[0]):\n",
        "            Yhat_tmp += int(X[h, i:i+W.shape[2]].dot(W[j, i, :]))\n",
        "        Yhat = np.append(Yhat, np.sum(Yhat_tmp, axis=0) + b[j])\n",
        "\n",
        "Yhat = Yhat.reshape(W.shape[0], N_out)\n",
        "print(Yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuq8qIL7tkvW"
      },
      "source": [
        "# バックワード\n",
        "delta_a = np.array([[10, 20],\n",
        "                    [20,30],\n",
        "                    [30,40]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrZLgh_ItkvX",
        "outputId": "be807f3f-a180-4777-f4a7-37a88de784a4"
      },
      "source": [
        "# Back Propergation\n",
        "\n",
        "# Xを更新\n",
        "aX = np.zeros([2,4])\n",
        "for j in range(W.shape[0]):\n",
        "    for i in range(W.shape[1]):\n",
        "        for h in range(W.shape[2]):\n",
        "            for k in range(N_out):\n",
        "                aX[i, h+k] += W[j, i, h] * delta_a[j, k]\n",
        "print(\"aX={}\".format(aX))\n",
        "\n",
        "# Wを更新\n",
        "aW = np.zeros([3,2,3])\n",
        "for j in range(W.shape[0]):\n",
        "    for i in range(W.shape[1]):\n",
        "        for h in range(W.shape[2]):\n",
        "            for k in range(N_out):\n",
        "                aW[j, i, h] += X[i, h+k] * delta_a[j, k]\n",
        "print(\"aW={}\".format(aW))\n",
        "\n",
        "# Bを更新\n",
        "aB = np.sum(delta_a, axis=1)\n",
        "print(\"aB={}\".format(aB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aX=[[ 60. 150. 150.  90.]\n",
            " [ 60. 150. 150.  90.]]\n",
            "aW=[[[ 50.  80. 110.]\n",
            "  [ 80. 110. 140.]]\n",
            "\n",
            " [[ 80. 130. 180.]\n",
            "  [130. 180. 230.]]\n",
            "\n",
            " [[110. 180. 250.]\n",
            "  [180. 250. 320.]]]\n",
            "aB=[30 50 70]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I-vR9FjtkvX"
      },
      "source": [
        "### 【問題6】（アドバンス課題）ミニバッチへの対応"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQy9wzxctkvX"
      },
      "source": [
        "# フォワード\n",
        "X=np.array([[1, 2, 3, 4], [2, 3, 4, 5]]*3).reshape(3,2,4)\n",
        "W = np.ones((3, 2, 3))\n",
        "B=np.array([1, 2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LhgRNnvtkvX",
        "outputId": "bb395748-2017-40b8-ad43-dde4be2401aa"
      },
      "source": [
        "# Forward Propergation\n",
        "# Xの要素の位置をストライドして計算\n",
        "\n",
        "pad=0\n",
        "strd=1\n",
        "\n",
        "N_out = int((X.shape[2] + 2*pad - W.shape[2]) / strd) + 1 # 【問題２】1次元畳み込み後の出力サイズの計算\n",
        "\n",
        "a = np.array([])\n",
        "for n in range(X.shape[0]):\n",
        "    Yhat = np.array([])\n",
        "    for j in range(N_out):\n",
        "        Yhat_tmp = 0\n",
        "        for i in range(X.shape[1]): # ストライドする分はループが必要か\n",
        "            Yhat_tmp += X[n, i, j:j+W.shape[2]].dot(W[n, i, :])\n",
        "        Yhat = np.append(Yhat, np.sum(Yhat_tmp, axis=0) + B[n])\n",
        "            \n",
        "    a = np.append(a, Yhat)\n",
        "    \n",
        "a = a.reshape(X.shape[0], N_out)\n",
        "\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DzWiEqttkvY"
      },
      "source": [
        "# バックワード\n",
        "delta_a = np.array([[10, 20],\n",
        "                    [20,30],\n",
        "                    [30,40]]*3).reshape(3,3,2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqhFfcZmtkvY",
        "outputId": "05ff7aa9-f004-48d3-f492-66be379e807b"
      },
      "source": [
        "# Back Propergation\n",
        "\n",
        "# Xを更新\n",
        "aX = np.zeros(X.shape)\n",
        "for n in range(X.shape[0]):\n",
        "    for j in range(W.shape[0]):\n",
        "        for i in range(W.shape[1]):\n",
        "            for h in range(W.shape[2]):\n",
        "                for k in range(N_out):\n",
        "                    aX[n, i, h+k] += W[j, i, h] * delta_a[n, j, k]\n",
        "print(\"aX={}\".format(aX))\n",
        "\n",
        "# Wを更新\n",
        "aW = np.zeros([3,2,3])\n",
        "for n in range(X.shape[0]):\n",
        "    for j in range(W.shape[0]):\n",
        "        for i in range(W.shape[1]):\n",
        "            for h in range(W.shape[2]):\n",
        "                for k in range(N_out):\n",
        "                    aW[j, i, h] += X[n, i, h+k] * delta_a[n, j, k]\n",
        "print(\"aW={}\".format(aW))\n",
        "\n",
        "# Bを更新\n",
        "aB = np.sum(delta_a, axis=1)\n",
        "print(\"aB={}\".format(aB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aX=[[[ 60. 150. 150.  90.]\n",
            "  [ 60. 150. 150.  90.]]\n",
            "\n",
            " [[ 60. 150. 150.  90.]\n",
            "  [ 60. 150. 150.  90.]]\n",
            "\n",
            " [[ 60. 150. 150.  90.]\n",
            "  [ 60. 150. 150.  90.]]]\n",
            "aW=[[[150. 240. 330.]\n",
            "  [240. 330. 420.]]\n",
            "\n",
            " [[240. 390. 540.]\n",
            "  [390. 540. 690.]]\n",
            "\n",
            " [[330. 540. 750.]\n",
            "  [540. 750. 960.]]]\n",
            "aB=[[60 90]\n",
            " [60 90]\n",
            " [60 90]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PlG-P68tkvY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}